from flask import Flask, request, render_template_string, send_from_directory
import cv2
import numpy as np
import torch
import uuid
import os
import traceback

# Import the pre-loaded models from model_loader
from model_loader import grounding_dino, sam_predictor, device

# Setup Flask App 
app = Flask(__name__)

# Create a directory to store uploaded and generated images
os.makedirs("static/images", exist_ok=True)

# Main Inference Function
def run_segmentation(image_bytes: bytes, prompt: str):
    try:
        # Validate inputs
        if not image_bytes:
            raise ValueError("No image data provided")
        
        if not prompt or not prompt.strip():
            raise ValueError("No prompt provided")
        
        # Convert image bytes to an OpenCV image
        nparr = np.frombuffer(image_bytes, np.uint8)
        source_image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if source_image is None:
            raise ValueError("Invalid image format. Please upload a valid image file.")
        
        # Check image dimensions
        height, width = source_image.shape[:2]
        if height == 0 or width == 0:
            raise ValueError("Invalid image dimensions")
            
        print(f"Processing image with dimensions: {width}x{height}")
        
        # Detect with GroundingDINO
        detections, phrases = grounding_dino.predict_with_caption(
            image=source_image,
            caption=prompt,
            box_threshold=0.35,
            text_threshold=0.25
        )

        # Check if any objects were detected
        if detections is None or len(detections.xyxy) == 0:
            print(f"No objects detected for prompt: '{prompt}'")
            return None, None # No object detected

        print(f"Detected {len(detections.xyxy)} objects with confidence scores: {detections.confidence}")

        # Segment with MobileSAM
        sam_predictor.set_image(source_image)
        
        # Convert detections to the correct format for SAM
        input_boxes = torch.tensor(detections.xyxy, device=device)
        
        # Ensure boxes are in the correct format [x1, y1, x2, y2]
        if input_boxes.dim() == 1:
            input_boxes = input_boxes.unsqueeze(0)
        
        print(f"Input boxes shape: {input_boxes.shape}")
        print(f"Input boxes: {input_boxes}")

        try:
            # Use predict method instead of predict_torch for better compatibility
            masks, scores, logits = sam_predictor.predict(
                point_coords=None,
                point_labels=None,
                box=input_boxes[0].cpu().numpy(),  # Use first box
                multimask_output=False,
            )
            
            if masks is None or len(masks) == 0:
                print("No masks generated by MobileSAM")
                return None, None
                
            # Create a binary mask
            final_mask = masks[0]  # Use first mask
            binary_mask = (final_mask > 0).astype(np.uint8) * 255
            
            print(f"Successfully generated mask with shape: {binary_mask.shape}")
            print(f"Mask values range: {final_mask.min()} to {final_mask.max()}")
            
        except Exception as e:
            print(f"Error in MobileSAM prediction: {str(e)}")
            # Try alternative approach with point prompts
            try:
                print("Trying alternative approach with point prompts...")
                # Get center point of the bounding box
                box = detections.xyxy[0]
                center_x = int((box[0] + box[2]) / 2)
                center_y = int((box[1] + box[3]) / 2)
                
                masks, scores, logits = sam_predictor.predict(
                    point_coords=np.array([[center_x, center_y]]),
                    point_labels=np.array([1]),  # 1 for foreground point
                    multimask_output=False,
                )
                
                if masks is not None and len(masks) > 0:
                    final_mask = masks[0]
                    binary_mask = (final_mask > 0).astype(np.uint8) * 255
                    print(f"Successfully generated mask with point prompts, shape: {binary_mask.shape}")
                else:
                    print("No masks generated with point prompts")
                    return None, None
                    
            except Exception as e2:
                print(f"Error in alternative MobileSAM prediction: {str(e2)}")
                return None, None

        # Create a copy of the original image for visualization
        result_image = source_image.copy()
        
        # Create a colored overlay for the segmentation mask
        overlay = np.zeros_like(source_image)
        overlay[binary_mask > 0] = [0, 255, 0]  # Green overlay for segmentation
        
        # Blend the overlay with the original image
        alpha = 0.3  # Transparency factor
        result_image = cv2.addWeighted(result_image, 1, overlay, alpha, 0)
        
        # Draw bounding boxes
        for box in detections.xyxy:
            x1, y1, x2, y2 = map(int, box)
            # Draw rectangle with red color and thickness 2
            cv2.rectangle(result_image, (x1, y1), (x2, y2), (0, 0, 255), 2)
            
            # Add label with confidence score
            label = f"{prompt}"
            # Get text size
            (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
            # Draw background rectangle for text
            cv2.rectangle(result_image, (x1, y1 - text_height - 10), (x1 + text_width + 10, y1), (0, 0, 255), -1)
            # Draw text
            cv2.putText(result_image, label, (x1 + 5, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

        # Generate unique filenames to avoid conflicts
        unique_id = uuid.uuid4()
        original_filename = f"static/images/{unique_id}_original.png"
        result_filename = f"static/GeneratedImages/{unique_id}_result.png"

        # Ensure the directories exist
        os.makedirs("static/images", exist_ok=True)
        os.makedirs("static/GeneratedImages", exist_ok=True)

        # Save images
        cv2.imwrite(original_filename, source_image)
        cv2.imwrite(result_filename, result_image)
        
        # Verify files were created
        if not os.path.exists(original_filename) or not os.path.exists(result_filename):
            raise ValueError("Failed to save processed images")

        return original_filename, result_filename
        
    except Exception as e:
        print(f"Error in run_segmentation: {str(e)}")
        return None, None

# HTML for web interface
HTML_TEMPLATE = """
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Food Segmentation With GroundingDINO and MobileSAM</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: #333;
            line-height: 1.6;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 40px 20px;
        }

        .header {
            text-align: center;
            margin-bottom: 50px;
            color: white;
        }

        .header h1 {
            font-size: 3rem;
            font-weight: 700;
            margin-bottom: 10px;
            text-shadow: 0 2px 4px rgba(0,0,0,0.3);
        }

        .header p {
            font-size: 1.2rem;
            opacity: 0.9;
            font-weight: 300;
        }

        .main-card {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(20px);
            border-radius: 24px;
            padding: 40px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            border: 1px solid rgba(255,255,255,0.2);
            margin-bottom: 30px;
        }

        .form-section {
            margin-bottom: 40px;
        }

        .section-title {
            font-size: 1.5rem;
            font-weight: 600;
            color: #2d3748;
            margin-bottom: 20px;
            display: flex;
            align-items: center;
            gap: 12px;
        }

        .section-title i {
            color: #667eea;
        }

        .form-group {
            margin-bottom: 25px;
        }

        .form-label {
            display: block;
            margin-bottom: 8px;
            font-weight: 500;
            color: #4a5568;
            font-size: 0.95rem;
        }

        .file-upload-area {
            border: 2px dashed #cbd5e0;
            border-radius: 12px;
            padding: 40px 20px;
            text-align: center;
            transition: all 0.3s ease;
            cursor: pointer;
            background: #f7fafc;
        }

        .file-upload-area:hover {
            border-color: #667eea;
            background: #edf2f7;
        }

        .file-upload-area.dragover {
            border-color: #667eea;
            background: #e6fffa;
        }

        .file-upload-icon {
            font-size: 3rem;
            color: #a0aec0;
            margin-bottom: 15px;
        }

        .file-upload-text {
            color: #718096;
            font-size: 1.1rem;
            margin-bottom: 10px;
        }

        .file-upload-hint {
            color: #a0aec0;
            font-size: 0.9rem;
        }

        .file-input {
            display: none;
        }

        .text-input {
            width: 100%;
            padding: 16px 20px;
            border: 2px solid #e2e8f0;
            border-radius: 12px;
            font-size: 1rem;
            transition: all 0.3s ease;
            background: white;
        }

        .text-input:focus {
            outline: none;
            border-color: #667eea;
            box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
        }

        .text-input::placeholder {
            color: #a0aec0;
        }

        .prompt-suggestions {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            margin-top: 12px;
        }

        .suggestion-chip {
            background: #edf2f7;
            color: #4a5568;
            padding: 6px 12px;
            border-radius: 20px;
            font-size: 0.85rem;
            cursor: pointer;
            transition: all 0.2s ease;
            border: none;
        }

        .suggestion-chip:hover {
            background: #667eea;
            color: white;
            transform: translateY(-1px);
        }

        .submit-btn {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 16px 32px;
            border: none;
            border-radius: 12px;
            font-size: 1.1rem;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            width: 100%;
            position: relative;
            overflow: hidden;
        }

        .submit-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 25px rgba(102, 126, 234, 0.3);
        }

        .submit-btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
        }

        .submit-btn i {
            margin-right: 8px;
        }

        .loading-container {
            text-align: center;
            padding: 40px 20px;
            display: none;
        }

        .loading-spinner {
            width: 60px;
            height: 60px;
            border: 4px solid #f3f4f6;
            border-top: 4px solid #667eea;
            border-radius: 50%;
            animation: spin 1s linear infinite;
            margin: 0 auto 20px;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .loading-text {
            color: #4a5568;
            font-size: 1.1rem;
            font-weight: 500;
        }

        .error-container {
            background: #fed7d7;
            color: #c53030;
            padding: 16px 20px;
            border-radius: 12px;
            margin: 20px 0;
            display: none;
            border-left: 4px solid #e53e3e;
        }

        .results-container {
            margin-top: 40px;
            display: none;
        }

        .results-header {
            text-align: center;
            margin-bottom: 30px;
        }

        .results-title {
            font-size: 2rem;
            font-weight: 600;
            color: #2d3748;
            margin-bottom: 10px;
        }

        .results-subtitle {
            color: #718096;
            font-size: 1.1rem;
        }

        .image-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin-top: 30px;
        }

        .image-card {
            background: white;
            border-radius: 16px;
            padding: 20px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.05);
            transition: transform 0.3s ease;
        }

        .image-card:hover {
            transform: translateY(-5px);
        }

        .image-title {
            font-size: 1.2rem;
            font-weight: 600;
            color: #2d3748;
            margin-bottom: 15px;
            text-align: center;
        }

        .image-wrapper {
            position: relative;
            border-radius: 12px;
            overflow: hidden;
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        }

        .image-wrapper img {
            width: 100%;
            height: auto;
            display: block;
            transition: transform 0.3s ease;
        }

        .image-wrapper:hover img {
            transform: scale(1.02);
        }

        .success-animation {
            animation: fadeInUp 0.6s ease-out;
        }

        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .file-preview {
            margin-top: 15px;
            display: none;
        }

        .file-preview img {
            max-width: 200px;
            max-height: 150px;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }

        @media (max-width: 768px) {
            .container {
                padding: 20px 15px;
            }

            .header h1 {
                font-size: 2rem;
            }

            .main-card {
                padding: 25px 20px;
            }

            .image-grid {
                grid-template-columns: 1fr;
                gap: 20px;
            }

            .submit-btn {
                padding: 14px 24px;
                font-size: 1rem;
            }
        }

        .pulse {
            animation: pulse 2s infinite;
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1><i class="fas fa-utensils"></i> Food Segmentation With GroundingDINO and MobileSAM</h1>
            <p>Upload an image and describe the food item to get precise segmentation result</p>
        </div>

        <div class="main-card">
            <form id="upload-form" enctype="multipart/form-data">
                <div class="form-section">
                    <div class="section-title">
                        <i class="fas fa-image"></i>
                        Upload Image
                    </div>
                    
                    <div class="form-group">
                        <label class="form-label">Select an image to upload</label>
                        <div class="file-upload-area" id="file-upload-area">
                            <div class="file-upload-icon">
                                <i class="fas fa-cloud-upload-alt"></i>
                            </div>
                            <div class="file-upload-text">Click to upload or drag and drop</div>
                            <div class="file-upload-hint">Supports: JPG, PNG, GIF, BMP (Max 10MB)</div>
                            <input type="file" name="image_file" id="image_file" accept="image/*" class="file-input" required>
                        </div>
                        <div class="file-preview" id="file-preview"></div>
                    </div>
                </div>

                <div class="form-section">
                    <div class="section-title">
                        <i class="fas fa-comment"></i>
                        Describe the Food
                    </div>
                    
                    <div class="form-group">
                        <label class="form-label">Enter a food prompt</label>
                        <input type="text" name="prompt" id="prompt" class="text-input" 
                               placeholder="e.g., Waakye, Popcorn, Mango, Sliced Yam, Boiled Egg" required>
                        
                        <div class="prompt-suggestions">
                            <button type="button" class="suggestion-chip" onclick="setPrompt('Waakye')">Waakye</button>
                            <button type="button" class="suggestion-chip" onclick="setPrompt('Popcorn')">White Popcorn</button>
                            <button type="button" class="suggestion-chip" onclick="setPrompt('Mango')">Sliced Mango</button>
                            <button type="button" class="suggestion-chip" onclick="setPrompt('Boiled Egg')">Boiled Egg</button>
                            <button type="button" class="suggestion-chip" onclick="setPrompt('Sliced Yam')">Sliced Yam</button>
                            <button type="button" class="suggestion-chip" onclick="setPrompt('Tomato')">Tomato Stew</button>
                        </div>
                    </div>
                </div>

                <button type="submit" id="submit-btn" class="submit-btn">
                    <i class="fas fa-magic"></i>
                    Segment Food
                </button>
            </form>

            <div id="loading" class="loading-container">
                <div class="loading-spinner"></div>
                <div class="loading-text">Processing your image...</div>
            </div>

            <div id="error" class="error-container"></div>

            <div id="results" class="results-container">
                <div class="results-header">
                    <div class="results-title">Segmentation Results</div>
                    <div class="results-subtitle">Your food item has been successfully segmented</div>
                </div>
                
                <div class="image-grid">
                    <div class="image-card">
                        <div class="image-title">Original Image</div>
                        <div class="image-wrapper">
                            <img id="original-image" src="" alt="Original">
                        </div>
                    </div>
                    <div class="image-card">
                        <div class="image-title">Segmentation Result</div>
                        <div class="image-wrapper">
                            <img id="result-image" src="" alt="Segmented">
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        // File upload handling
        const fileUploadArea = document.getElementById('file-upload-area');
        const fileInput = document.getElementById('image_file');
        const filePreview = document.getElementById('file-preview');

        fileUploadArea.addEventListener('click', () => fileInput.click());
        
        fileUploadArea.addEventListener('dragover', (e) => {
            e.preventDefault();
            fileUploadArea.classList.add('dragover');
        });

        fileUploadArea.addEventListener('dragleave', () => {
            fileUploadArea.classList.remove('dragover');
        });

        fileUploadArea.addEventListener('drop', (e) => {
            e.preventDefault();
            fileUploadArea.classList.remove('dragover');
            const files = e.dataTransfer.files;
            if (files.length > 0) {
                fileInput.files = files;
                handleFileSelect(files[0]);
            }
        });

        fileInput.addEventListener('change', (e) => {
            if (e.target.files.length > 0) {
                handleFileSelect(e.target.files[0]);
            }
        });

        function handleFileSelect(file) {
            if (file && file.type.startsWith('image/')) {
                const reader = new FileReader();
                reader.onload = function(e) {
                    filePreview.innerHTML = `<img src="${e.target.result}" alt="Preview">`;
                    filePreview.style.display = 'block';
                };
                reader.readAsDataURL(file);
            }
        }

        // Prompt suggestions
        function setPrompt(prompt) {
            document.getElementById('prompt').value = prompt;
        }

        // Form submission
        document.getElementById('upload-form').addEventListener('submit', async function(e) {
            e.preventDefault();
            
            const formData = new FormData(this);
            const loading = document.getElementById('loading');
            const error = document.getElementById('error');
            const results = document.getElementById('results');
            const submitBtn = document.getElementById('submit-btn');
            
            // Validate inputs
            const imageFile = document.getElementById('image_file').files[0];
            const prompt = document.getElementById('prompt').value.trim();
            
            if (!imageFile) {
                showError('Please select an image file.');
                return;
            }
            
            if (!prompt) {
                showError('Please enter a prompt describing the food item.');
                return;
            }
            
            // Show loading
            loading.style.display = 'block';
            error.style.display = 'none';
            results.style.display = 'none';
            submitBtn.disabled = true;
            submitBtn.innerHTML = '<i class="fas fa-spinner fa-spin"></i> Processing...';
            
            try {
                const response = await fetch('/segment', {
                    method: 'POST',
                    body: formData
                });
                
                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }
                
                const result = await response.json();
                
                if (result.success) {
                    // Add timestamp to prevent caching
                    const timestamp = new Date().getTime();
                    document.getElementById('original-image').src = result.original_path + '?t=' + timestamp;
                    document.getElementById('result-image').src = result.result_path + '?t=' + timestamp;
                    
                    // Show results with animation
                    results.style.display = 'block';
                    results.classList.add('success-animation');
                    
                    // Scroll to results
                    results.scrollIntoView({ behavior: 'smooth' });
                } else {
                    showError(result.error || 'An error occurred during processing.');
                }
            } catch (err) {
                console.error('Error:', err);
                showError('An error occurred while processing the image. Please try again.');
            } finally {
                loading.style.display = 'none';
                submitBtn.disabled = false;
                submitBtn.innerHTML = '<i class="fas fa-magic"></i> Segment Food';
            }
        });
        
        function showError(message) {
            const error = document.getElementById('error');
            error.textContent = message;
            error.style.display = 'block';
            error.scrollIntoView({ behavior: 'smooth' });
        }

        // Add some interactive effects
        document.addEventListener('DOMContentLoaded', function() {
            // Add pulse animation to submit button on page load
            const submitBtn = document.getElementById('submit-btn');
            submitBtn.classList.add('pulse');
            
            setTimeout(() => {
                submitBtn.classList.remove('pulse');
            }, 2000);
        });
    </script>
</body>
</html>
"""

# Web App Routes

@app.route('/')
def index():
    """The main page with the upload form."""
    return HTML_TEMPLATE

@app.route('/health')
def health_check():
    return {
        'status': 'healthy',
        'models_loaded': {
            'grounding_dino': grounding_dino is not None,
            'sam_predictor': sam_predictor is not None
        },
        'device': str(device),
        'sam_predictor_type': type(sam_predictor).__name__ if sam_predictor else None
    }

@app.route('/test_sam')
def test_sam():
    if sam_predictor is None:
        return {'error': 'SAM predictor not loaded'}
    
    try:
        # Create simple test image
        test_image = np.zeros((100, 100, 3), dtype=np.uint8)
        test_image[25:75, 25:75] = [255, 255, 255]  # White square
        
        # Set the image
        sam_predictor.set_image(test_image)
        
        # Try to predict with a simple box
        test_box = np.array([30, 30, 70, 70])
        
        masks, scores, logits = sam_predictor.predict(
            point_coords=None,
            point_labels=None,
            box=test_box,
            multimask_output=False,
        )
        
        return {
            'success': True,
            'masks_shape': masks.shape if masks is not None else None,
            'scores': scores.tolist() if scores is not None else None,
            'test_box': test_box.tolist()
        }
        
    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }

@app.route('/segment', methods=['POST'])
def segment():
    try:
        # Check if models are loaded
        if grounding_dino is None:
            return {'success': False, 'error': 'GroundingDINO model is not loaded. Check the server logs.'}
        
        if sam_predictor is None:
            return {'success': False, 'error': 'MobileSAM model is not loaded. Check the server logs.'}
        
        if 'image_file' not in request.files:
            return {'success': False, 'error': 'No image file provided.'}
        
        image_file = request.files['image_file']
        prompt = request.form.get('prompt', '').strip()
        
        if not image_file or image_file.filename == '':
            return {'success': False, 'error': 'Please select a valid image file.'}
        
        if not prompt:
            return {'success': False, 'error': 'Please provide a prompt describing the food item.'}
        
        # Check file type
        allowed_extensions = {'png', 'jpg', 'jpeg', 'gif', 'bmp'}
        if '.' not in image_file.filename or \
           image_file.filename.rsplit('.', 1)[1].lower() not in allowed_extensions:
            return {'success': False, 'error': 'Upload a valid image file (PNG, JPG, JPEG, GIF, BMP).'}
        
        # Read image bytes
        image_bytes = image_file.read()
        
        if len(image_bytes) == 0:
            return {'success': False, 'error': 'The uploaded file is empty.'}
        
        # Run model
        original_path, result_path = run_segmentation(image_bytes, prompt)
        
        if original_path is None or result_path is None:
            return {'success': False, 'error': 'Could not detect the specified object. Try a different prompt or image. Make sure your prompt clearly describes the food item you want to segment (e.g., "the boiled Egg", "Red Tomato Stew", "Green Lettuce", "Sliced Watermelon").'}
        
        return {
            'success': True,
            'original_path': f'/{original_path}',
            'result_path': f'/{result_path}'
        }
        
    except Exception as e:
        print(f"Error in segment route: {str(e)}")
        return {'success': False, 'error': f'An error occurred during processing: {str(e)}'}

# Route to serve static files
@app.route('/static/<path:filename>')
def static_files(filename):
    return send_from_directory('static', filename)

# Route to serve images
@app.route('/static/images/<path:filename>')
def serve_images(filename):
    return send_from_directory('static/images', filename)

if __name__ == "__main__":
    app.run(debug=True, host='0.0.0.0', port=5001)